"""
KBO ì „ì²´ ì‹œë¦¬ì¦ˆ íƒ€ì ê¸°ë¡ í¬ë¡¤ëŸ¬
- ì •ê·œì‹œì¦Œ, ì‹œë²”ê²½ê¸°, ì™€ì¼ë“œì¹´ë“œ, ì¤€í”Œë ˆì´ì˜¤í”„, í”Œë ˆì´ì˜¤í”„, í•œêµ­ì‹œë¦¬ì¦ˆ

Usage:
    # 2025ë…„ ëª¨ë“  ì‹œë¦¬ì¦ˆ í¬ë¡¤ë§
    python -m src.crawlers.player_batting_all_series_crawler --year 2025 --save

    # íŠ¹ì • ì‹œë¦¬ì¦ˆë§Œ
    python -m src.crawlers.player_batting_all_series_crawler --year 2025 --series regular --save
    python -m src.crawlers.player_batting_all_series_crawler --year 2025 --series exhibition --save
"""
import argparse
import os
import re
import time
from datetime import datetime
from typing import Dict, List, Optional

from playwright.sync_api import sync_playwright, Page

from src.repositories.safe_batting_repository import save_batting_stats_safe
from src.utils.team_mapping import get_team_code, get_team_mapping_for_year
from src.utils.playwright_blocking import install_sync_resource_blocking


def get_team_code_mapping() -> Dict[str, str]:
    """íŒ€ëª… â†’ íŒ€ ì½”ë“œ ë§¤í•‘ (í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€)"""
    return {
        'LG': 'LG',
        'NC': 'NC', 
        'KT': 'KT',
        'ì‚¼ì„±': 'SS',
        'ë¡¯ë°': 'LT',
        'ë‘ì‚°': 'OB',
        'KIA': 'HT',
        'í•œí™”': 'HH',
        'í‚¤ì›€': 'WO',
        'SSG': 'SK'
    }


def get_series_mapping() -> Dict[str, Dict[str, str]]:
    """ì‹œë¦¬ì¦ˆ ì´ë¦„ê³¼ ì„ íƒ ê°’ ë§¤í•‘ (ì‹¤ì œ í˜ì´ì§€ì—ì„œ í™•ì¸ëœ ê°’)"""
    return {
        'regular': {
            'name': 'KBO ì •ê·œì‹œì¦Œ',
            'value': '0',
            'league': 'REGULAR'
        },
        'exhibition': {
            'name': 'KBO ì‹œë²”ê²½ê¸°',
            'value': '1',
            'league': 'EXHIBITION'
        },
        'wildcard': {
            'name': 'KBO ì™€ì¼ë“œì¹´ë“œ',
            'value': '4',
            'league': 'WILDCARD'
        },
        'semi_playoff': {
            'name': 'KBO ì¤€í”Œë ˆì´ì˜¤í”„',
            'value': '3',
            'league': 'SEMI_PLAYOFF'
        },
        'playoff': {
            'name': 'KBO í”Œë ˆì´ì˜¤í”„',
            'value': '5',
            'league': 'PLAYOFF'
        },
        'korean_series': {
            'name': 'KBO í•œêµ­ì‹œë¦¬ì¦ˆ',
            'value': '7',
            'league': 'KOREAN_SERIES'
        }
    }


def safe_parse_number(value_str: str, data_type: type, allow_zero: bool = True) -> Optional[int | float]:
    """
    ì•ˆì „í•˜ê²Œ ìˆ«ìë¥¼ íŒŒì‹±í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        value_str: íŒŒì‹±í•  ë¬¸ìì—´
        data_type: ë³€í™˜í•  ë°ì´í„° íƒ€ì… (int ë˜ëŠ” float)
        allow_zero: 0 ê°’ì„ í—ˆìš©í• ì§€ ì—¬ë¶€
    
    Returns:
        íŒŒì‹±ëœ ìˆ«ì ë˜ëŠ” None
    """
    if not value_str:
        return None
    
    value_str = value_str.strip()
    
    # ë¹ˆ ë¬¸ìì—´, "-", "N/A" ë“±ì€ Noneìœ¼ë¡œ ì²˜ë¦¬
    if not value_str or value_str in ['-', 'N/A', '']:
        return None
    
    try:
        parsed_value = data_type(value_str)
        # 0ì€ ì‹¤ì œ ê°’ì´ë¯€ë¡œ 0ìœ¼ë¡œ ì €ì¥
        return parsed_value
    except (ValueError, TypeError):
        return None


def _extract_rows_fast(page: Page, table_selector: str = "table") -> Optional[List[Dict[str, object]]]:
    try:
        payload = page.evaluate(
            """
            (selector) => {
                const table = document.querySelector(selector);
                if (!table) return null;
                const body = table.tBodies && table.tBodies.length ? table.tBodies[0] : table;
                const rows = Array.from(body.querySelectorAll('tr'));
                return rows.map((row) => {
                    const cells = Array.from(row.querySelectorAll('td')).map(td => (td.innerText || '').trim());
                    const link = row.querySelector('td:nth-child(2) a');
                    return {
                        cells,
                        linkText: link ? (link.innerText || '').trim() : null,
                        linkHref: link ? link.getAttribute('href') : null,
                    };
                });
            }
            """,
            table_selector,
        )
        return payload or []
    except Exception:
        return None


def _extract_player_id_from_href(href: Optional[str]) -> Optional[int]:
    if not href:
        return None
    match = re.search(r"playerId=(\d+)", href)
    return int(match.group(1)) if match else None


def _is_basic2_headers(headers: List[str]) -> bool:
    basic2_indicators = ["BB", "ë³¼ë„·", "IBB", "HBP", "SLG", "OBP", "OPS"]
    combined = "".join(headers)
    return any(indicator in combined for indicator in basic2_indicators)


def _build_batting_data(
    cells: List[str],
    player_id: int,
    player_name: str,
    team_code: str,
    series_key: str,
    is_basic2: bool,
) -> Dict:
    def cell(idx: int) -> Optional[str]:
        return cells[idx] if len(cells) > idx else None

    if series_key == "regular":
        if is_basic2:
            return {
                "player_id": player_id,
                "player_name": player_name,
                "team_code": team_code,
                "avg": safe_parse_number(cell(3), float),
                "walks": safe_parse_number(cell(4), int),
                "intentional_walks": safe_parse_number(cell(5), int),
                "hbp": safe_parse_number(cell(6), int),
                "strikeouts": safe_parse_number(cell(7), int),
                "gdp": safe_parse_number(cell(8), int),
                "slg": safe_parse_number(cell(9), float),
                "obp": safe_parse_number(cell(10), float),
                "ops": safe_parse_number(cell(11), float),
                "extra_stats": {
                    "multi_hits": safe_parse_number(cell(12), int),
                    "risp_avg": safe_parse_number(cell(13), float),
                    "pinch_hit_avg": safe_parse_number(cell(14), float),
                },
            }
        return {
            "player_id": player_id,
            "player_name": player_name,
            "team_code": team_code,
            "avg": safe_parse_number(cell(3), float),
            "games": safe_parse_number(cell(4), int),
            "plate_appearances": safe_parse_number(cell(5), int),
            "at_bats": safe_parse_number(cell(6), int),
            "runs": safe_parse_number(cell(7), int),
            "hits": safe_parse_number(cell(8), int),
            "doubles": safe_parse_number(cell(9), int),
            "triples": safe_parse_number(cell(10), int),
            "home_runs": safe_parse_number(cell(11), int),
            "total_bases": safe_parse_number(cell(12), int),
            "rbi": safe_parse_number(cell(13), int),
            "sacrifice_hits": safe_parse_number(cell(14), int),
            "sacrifice_flies": safe_parse_number(cell(15), int),
        }

    return {
        "player_id": player_id,
        "player_name": player_name,
        "team_code": team_code,
        "avg": safe_parse_number(cell(3), float),
        "games": safe_parse_number(cell(4), int),
        "plate_appearances": safe_parse_number(cell(5), int),
        "at_bats": safe_parse_number(cell(6), int),
        "hits": safe_parse_number(cell(7), int),
        "doubles": safe_parse_number(cell(8), int),
        "triples": safe_parse_number(cell(9), int),
        "home_runs": safe_parse_number(cell(10), int),
        "rbi": safe_parse_number(cell(11), int),
        "stolen_bases": safe_parse_number(cell(12), int),
        "caught_stealing": safe_parse_number(cell(13), int),
        "walks": safe_parse_number(cell(14), int),
        "hbp": safe_parse_number(cell(15), int),
        "strikeouts": safe_parse_number(cell(16), int),
        "gdp": safe_parse_number(cell(17), int),
        "extra_stats": {"errors": safe_parse_number(cell(18), int)},
    }


def _parse_batting_stats_table_fast(page: Page, series_key: str, year: int = 2025) -> List[Dict]:
    """
    Parse batting table using JS extraction for reduced RPC.
    """
    team_mapping = get_team_mapping_for_year(year)

    extraction_script = """
    () => {
        const rows = document.querySelectorAll('table tbody tr');
        if (rows.length === 0) return null;

        const headers = Array.from(document.querySelectorAll('table thead th')).map(th => th.innerText.trim());
        const basic2_indicators = ['BB', 'ë³¼ë„·', 'IBB', 'HBP', 'SLG', 'OBP', 'OPS'];
        const is_basic2 = basic2_indicators.some(ind => headers.join('').includes(ind));

        const results = [];
        rows.forEach(row => {
            const cells = Array.from(row.querySelectorAll('td'));
            if (cells.length < 10) return;

            const nameLink = cells[1].querySelector('a');
            if (!nameLink) return;

            const playerName = nameLink.innerText.trim();
            const href = nameLink.getAttribute('href');
            const idMatch = href ? href.match(/playerId=(\d+)/) : null;
            if (!idMatch) return;
            const playerId = parseInt(idMatch[1], 10);

            const teamName = cells[2].innerText.trim();
            results.push({
                player_id: playerId,
                player_name: playerName,
                team_name: teamName,
                raw_cells: cells.map(c => c.innerText.trim()),
            });
        });
        return { is_basic2, results };
    }
    """

    try:
        js_result = page.evaluate(extraction_script)
        if not js_result or not isinstance(js_result, dict) or not js_result.get("results"):
            return []

        extracted_rows = js_result["results"]
        is_basic2 = js_result.get("is_basic2", False)

        players_data = []
        for row in extracted_rows:
            player_id = row["player_id"]
            player_name = row["player_name"]
            team_name = row["team_name"]
            cells = row["raw_cells"]

            team_code = get_team_code(team_name, year)
            if not team_code:
                team_code = team_mapping.get(team_name, team_name)

            batting_data = _build_batting_data(
                cells=cells,
                player_id=player_id,
                player_name=player_name,
                team_code=team_code,
                series_key=series_key,
                is_basic2=is_basic2,
            )
            players_data.append(batting_data)

        return players_data
    except Exception as exc:
        print(f"âŒ í…Œì´ë¸” íŒŒì‹± ì˜¤ë¥˜ (JS): {exc}")
        return []


def _parse_batting_stats_table_legacy(page: Page, series_key: str, year: int = 2025) -> List[Dict]:
    team_mapping = get_team_mapping_for_year(year)
    try:
        table = page.query_selector("table")
        if not table:
            return []

        thead = table.query_selector("thead")
        headers = []
        if thead:
            header_cells = thead.query_selector_all("th")
            headers = [cell.inner_text().strip() for cell in header_cells]
        is_basic2 = _is_basic2_headers(headers) if headers else False

        tbody = table.query_selector("tbody")
        rows = tbody.query_selector_all("tr") if tbody else table.query_selector_all("tr")
        if not rows:
            return []

        players_data = []
        for row in rows:
            cell_nodes = row.query_selector_all("td")
            if len(cell_nodes) < 10:
                continue

            cells = [cell.inner_text().strip() for cell in cell_nodes]
            name_link = cell_nodes[1].query_selector("a")
            href = name_link.get_attribute("href") if name_link else None
            player_id = _extract_player_id_from_href(href)
            if not player_id:
                continue

            player_name = name_link.inner_text().strip() if name_link else (cells[1] if len(cells) > 1 else "")
            team_name = cells[2] if len(cells) > 2 else ""
            team_code = get_team_code(team_name, year)
            if not team_code:
                team_code = team_mapping.get(team_name, team_name)

            batting_data = _build_batting_data(
                cells=cells,
                player_id=player_id,
                player_name=player_name,
                team_code=team_code,
                series_key=series_key,
                is_basic2=is_basic2,
            )
            players_data.append(batting_data)

        return players_data
    except Exception as exc:
        print(f"âŒ í…Œì´ë¸” íŒŒì‹± ì˜¤ë¥˜ (Legacy): {exc}")
        return []


def parse_batting_stats_table(
    page: Page,
    series_key: str,
    year: int = 2025,
    use_fast: Optional[bool] = None,
) -> List[Dict]:
    if use_fast is None:
        use_fast = os.getenv("KBO_FAST_PARSE", "1") != "0"
    if use_fast:
        return _parse_batting_stats_table_fast(page, series_key, year)
    return _parse_batting_stats_table_legacy(page, series_key, year)


def go_to_next_page(page: Page, current_page_num: int) -> bool:
    """
    ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™ (1â†’2,3,4,5â†’ë‹¤ìŒâ†’6,7,8,9,10â†’ë‹¤ìŒ ë°˜ë³µ)
    
    Args:
        page: Playwright Page ê°ì²´
        current_page_num: í˜„ì¬ í˜ì´ì§€ ë²ˆí˜¸
    
    Returns:
        ì„±ê³µ ì—¬ë¶€ (ë§ˆì§€ë§‰ í˜ì´ì§€ì´ë©´ False)
    """
    try:
        # 1â†’2,3,4,5â†’ë‹¤ìŒâ†’6,7,8,9,10â†’ë‹¤ìŒ íŒ¨í„´
        if current_page_num % 5 == 0:  # 5í˜ì´ì§€ë§ˆë‹¤ "ë‹¤ìŒ" ë²„íŠ¼ í´ë¦­
            # ë‹¤ìŒ ë²„íŠ¼ ì°¾ê¸° (ì‹¤ì œ í˜ì´ì§€ êµ¬ì¡°ì— ë§ëŠ” ì…€ë ‰í„°)
            next_button_selector = 'a[href*="btnNext"]'
            next_button = page.query_selector(next_button_selector)
            
            if not next_button:
                print("ğŸ“„ ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # ë²„íŠ¼ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            if next_button.get_attribute("disabled") or "disabled" in (next_button.get_attribute("class") or ""):
                print("ğŸ“„ ë§ˆì§€ë§‰ í˜ì´ì§€ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
                return False
            
            next_button.click()
            page.wait_for_load_state('networkidle', timeout=30000)
            time.sleep(2)
            print(f"â¡ï¸ ë‹¤ìŒ ë²„íŠ¼ í´ë¦­ ({current_page_num}í˜ì´ì§€ í›„)")
            
        else:  # ê°œë³„ í˜ì´ì§€ ë²ˆí˜¸ í´ë¦­ (1,2,3,4,5 ë²”ìœ„ ë‚´)
            next_page_num = current_page_num + 1
            relative_page_num = ((next_page_num - 1) % 5) + 1  # 1~5 ë²”ìœ„ë¡œ ë³€í™˜
            
            # ì‹¤ì œ í˜ì´ì§€ êµ¬ì¡°ì— ë§ëŠ” ì…€ë ‰í„° ì‚¬ìš©
            page_button_selector = f'a[href*="btnNo{relative_page_num}"]'
            page_button = page.query_selector(page_button_selector)
            
            if page_button:
                page_button.click()
                page.wait_for_load_state('networkidle', timeout=30000)
                time.sleep(1)
                print(f"â¡ï¸ {next_page_num}í˜ì´ì§€ë¡œ ì´ë™ (btnNo{relative_page_num})")
            else:
                print(f"ğŸ“„ í˜ì´ì§€ {next_page_num} ë²„íŠ¼(btnNo{relative_page_num})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
        
        return True
        
    except Exception as e:
        print(f"âŒ í˜ì´ì§€ ì´ë™ ì‹¤íŒ¨: {e}")
        return False


def crawl_basic2_with_headers(page: Page, year: int, series_info: dict) -> Dict[int, Dict]:
    """
    ì •ê·œì‹œì¦Œìš© Basic2 í˜ì´ì§€ì—ì„œ ê° í—¤ë”ë¥¼ í´ë¦­í•˜ì—¬ ê³ ê¸‰ í†µê³„ ë°ì´í„° ìˆ˜ì§‘
    ìŠ¤í‚¤ë§ˆ ê¸°ì¤€: BB,IBB,HBP,SO,GDP,SLG,OBP,OPS,MH,RISP,PH-BA
    
    ì ‘ê·¼ ìˆœì„œ: íƒ€ì -> ì •ê·œì‹œì¦Œ ì„ íƒ -> ì—°ë„ ì„ íƒ -> "ë‹¤ìŒ" ë§í¬ í´ë¦­í•˜ì—¬ Basic2 ì ‘ê·¼
    """
    # Refactored: í—¤ë”ë³„ í´ë¦­ ëŒ€ì‹  ì „ì²´ í˜ì´ì§€ ìˆœíšŒë¡œ ë³€ê²½
    all_player_data = {}
    
    try:
        print(f"   ğŸ” Basic2 ì ‘ê·¼ì„ ìœ„í•´ Basic1ì—ì„œ ì‹œì‘...")
        
        # 1. Basic1 í˜ì´ì§€ë¡œ ì´ë™
        url = "https://www.koreabaseball.com/Record/Player/HitterBasic/Basic1.aspx"
        page.goto(url, wait_until='load', timeout=30000)
        page.wait_for_load_state('networkidle', timeout=30000)
        time.sleep(2)
        
        # 2. ì—°ë„ ì„ íƒ
        try:
            season_selector = 'select[name="ctl00$ctl00$ctl00$cphContents$cphContents$cphContents$ddlSeason$ddlSeason"]'
            page.select_option(season_selector, str(year))
            print(f"   âœ… {year}ë…„ ì—°ë„ ì„ íƒ")
            time.sleep(1)
        except Exception as e:
            print(f"   âš ï¸ ì—°ë„ ì„ íƒ ì¤‘ ì˜¤ë¥˜: {e}")
            return {}

        # 3. ì •ê·œì‹œì¦Œ ì„ íƒ
        try:
            series_selector = 'select[name="ctl00$ctl00$ctl00$cphContents$cphContents$cphContents$ddlSeries$ddlSeries"]'
            page.select_option(series_selector, value=series_info['value'])
            print(f"   âœ… {series_info['name']} ì„ íƒ")
            time.sleep(2)
        except Exception as e:
            print(f"   âš ï¸ ì‹œë¦¬ì¦ˆ ì„ íƒ ì¤‘ ì˜¤ë¥˜: {e}")
            return {}
        
        # 4. "ë‹¤ìŒ" ë§í¬ í´ë¦­í•˜ì—¬ Basic2ë¡œ ì´ë™
        try:
            next_link_selector = 'a[href="/Record/Player/HitterBasic/Basic2.aspx"]'
            next_link = page.query_selector(next_link_selector)
            
            # fallback find
            if not next_link:
                possible_selectors = ['a.next', 'a[href*="Basic2"]', 'a:has-text("ë‹¤ìŒ")']
                for sel in possible_selectors:
                    next_link = page.query_selector(sel)
                    if next_link: break
            
            if next_link:
                print(f"   ğŸ”— 'Basic2' ë‹¤ìŒ ë§í¬ í´ë¦­...")
                next_link.click()
                page.wait_for_load_state('networkidle', timeout=30000)
                time.sleep(3)
                
                if "Basic2" not in page.url:
                    print(f"   âš ï¸ Basic2 ì ‘ê·¼ ì‹¤íŒ¨, í˜„ì¬ URL: {page.url}")
                    return {}
            else:
                print(f"   âŒ Basic2ë¡œ ì´ë™í•˜ëŠ” 'ë‹¤ìŒ' ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return {}
                
        except Exception as e:
            print(f"   âš ï¸ Basic2 ì ‘ê·¼ ì¤‘ ì˜¤ë¥˜: {e}")
            return {}
        
        print(f"   ğŸ” Basic2 ì „ì²´ í˜ì´ì§€ ìˆœíšŒ ì‹œì‘...")
        
        # 5. Basic2 í˜ì´ì§€ ì „ì²´ ìˆœíšŒ
        page_num = 1
        while True:
            # í˜„ì¬ í˜ì´ì§€ ë°ì´í„° íŒŒì‹± using parse_batting_stats_table
            # This function automatically detects Basic2 headers via is_basic2 logic
            current_page_data = parse_batting_stats_table(page, "regular", year)
            
            for player_stat in current_page_data:
                pid = player_stat['player_id']
                # Basic2 data keys mapping
                # parse_batting_stats_table returns structured dict with keys like 'walks', 'ops' etc.
                if pid not in all_player_data:
                    all_player_data[pid] = player_stat
                else:
                    # Merge if needed, but usually we just want the Basic2 specific fields
                    # However, parse_batting_stats_table returns full record for that view.
                    # Since we are iterating full list, we just take it.
                    # Note: The caller might merge this with Basic1 data.
                    all_player_data[pid].update(player_stat)

            print(f"      âœ… {page_num}í˜ì´ì§€: {len(current_page_data)}ëª… ìˆ˜ì§‘")

            # ë‹¤ìŒ í˜ì´ì§€ ì´ë™
            if not go_to_next_page(page, page_num):
                break
            page_num += 1
            time.sleep(1)

        print(f"   âœ… Basic2 ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ: {len(all_player_data)}ëª…")
        
    except Exception as e:
        print(f"   âŒ Basic2 í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {e}")
    
    return all_player_data


def _parse_basic2_header_data_legacy(
    page: Page,
    current_header: str,
    description: str,
    year: int = 2025,
) -> Dict[int, Dict]:
    """
    Basic2 í˜ì´ì§€ì—ì„œ íŠ¹ì • í—¤ë” í´ë¦­ í›„ ë°ì´í„° íŒŒì‹±
    ê° í—¤ë” í´ë¦­ì‹œ í•´ë‹¹ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ëœ ì„ ìˆ˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘
    """
    players_data = {}
    team_mapping = get_team_mapping_for_year(year)

    try:
        table = page.query_selector("table")
        if not table:
            return players_data

        tbody = table.query_selector("tbody")
        if tbody:
            rows = tbody.query_selector_all("tr")
        else:
            rows = table.query_selector_all("tr")
        
        if len(rows) == 0:
            return players_data

        # í…Œì´ë¸” í—¤ë” êµ¬ì¡° í™•ì¸ (ë””ë²„ê¹…ìš©)
        thead = page.query_selector("thead")
        if thead:
            header_cells = thead.query_selector_all("th")
            headers = [cell.inner_text().strip() for cell in header_cells]
            print(f"      ğŸ” {description} ê¸°ì¤€ í…Œì´ë¸” í—¤ë”: {headers}")

        # ì²« ë²ˆì§¸ í–‰ ìƒ˜í”Œ í™•ì¸ (ë””ë²„ê¹…ìš©)
        if len(rows) > 0:
            first_row_cells = rows[0].query_selector_all("td")
            print(f"      ğŸ” {description} ê¸°ì¤€ ì²« í–‰ ë°ì´í„° ({len(first_row_cells)}ê°œ ì»¬ëŸ¼):")
            for i, cell in enumerate(first_row_cells[:10]):  # ì²˜ìŒ 10ê°œë§Œ
                content = cell.inner_text().strip()
                print(f"         [{i}]: '{content}'")

        for row_idx, row in enumerate(rows):
            cells = row.query_selector_all("td")
            
            if len(cells) < 5:  # ìµœì†Œ í•„ë“œ ìˆ˜ í™•ì¸
                continue

            try:
                # ì„ ìˆ˜ëª…ê³¼ ID ì¶”ì¶œ
                name_cell = cells[1]  # ì„ ìˆ˜ëª…
                name_link = name_cell.query_selector("a")
                
                if not name_link:
                    continue
                
                player_name = name_link.inner_text().strip()
                href = name_link.get_attribute("href")
                player_id = _extract_player_id_from_href(href)
                if not player_id:
                    continue
                
                # íŒ€ëª… ì¶”ì¶œ ë° ë™ì  ë§¤í•‘
                team_name = cells[2].inner_text().strip()
                team_code = get_team_code(team_name, year)
                if not team_code:
                    # ì •ì  ë§¤í•‘ í´ë°±
                    team_code = team_mapping.get(team_name, team_name)
                    print(f"âš ï¸ {year}ë…„ '{team_name}' íŒ€ ë§¤í•‘ ì‹¤íŒ¨, í´ë°±: {team_code}")

                # í—¤ë”ë³„ë¡œ í•´ë‹¹ ë°ì´í„°ë§Œ ì¶”ì¶œ
                batting_data = {
                    'player_id': player_id,
                    'player_name': player_name,
                    'team_code': team_code,
                }
                
                # Basic2 í…Œì´ë¸”ì˜ ì‹¤ì œ êµ¬ì¡°ì— ë§ê²Œ ë°ì´í„° ì¶”ì¶œ
                # í—¤ë”: ['ìˆœìœ„', 'ì„ ìˆ˜ëª…', 'íŒ€ëª…', 'AVG', 'BB', 'IBB', 'HBP', 'SO', 'GDP', 'SLG', 'OBP', 'OPS', 'MH', 'RISP', 'PH-BA']
                #       [0]    [1]    [2]    [3]   [4]   [5]   [6]    [7]   [8]    [9]    [10]   [11]   [12]   [13]    [14]
                
                # í—¤ë”ì— ë”°ë¥¸ ì •í™•í•œ ì»¬ëŸ¼ ìœ„ì¹˜ì—ì„œ ë°ì´í„° ì¶”ì¶œ
                if current_header == 'BB' and len(cells) > 4:
                    batting_data['walks'] = safe_parse_number(cells[4].inner_text().strip(), int)
                elif current_header == 'IBB' and len(cells) > 5:
                    batting_data['intentional_walks'] = safe_parse_number(cells[5].inner_text().strip(), int)
                elif current_header == 'HBP' and len(cells) > 6:
                    batting_data['hbp'] = safe_parse_number(cells[6].inner_text().strip(), int)
                elif current_header == 'SO' and len(cells) > 7:
                    batting_data['strikeouts'] = safe_parse_number(cells[7].inner_text().strip(), int)
                elif current_header == 'GDP' and len(cells) > 8:
                    batting_data['gdp'] = safe_parse_number(cells[8].inner_text().strip(), int)
                elif current_header == 'SLG' and len(cells) > 9:
                    batting_data['slg'] = safe_parse_number(cells[9].inner_text().strip(), float)
                elif current_header == 'OBP' and len(cells) > 10:
                    batting_data['obp'] = safe_parse_number(cells[10].inner_text().strip(), float)
                elif current_header == 'OPS' and len(cells) > 11:
                    batting_data['ops'] = safe_parse_number(cells[11].inner_text().strip(), float)
                elif current_header == 'MH' and len(cells) > 12:
                    if 'extra_stats' not in batting_data:
                        batting_data['extra_stats'] = {}
                    batting_data['extra_stats']['multi_hits'] = safe_parse_number(cells[12].inner_text().strip(), int)
                elif current_header == 'RISP' and len(cells) > 13:
                    if 'extra_stats' not in batting_data:
                        batting_data['extra_stats'] = {}
                    batting_data['extra_stats']['risp_avg'] = safe_parse_number(cells[13].inner_text().strip(), float)
                elif current_header == 'PH-BA' and len(cells) > 14:
                    if 'extra_stats' not in batting_data:
                        batting_data['extra_stats'] = {}
                    batting_data['extra_stats']['pinch_hit_avg'] = safe_parse_number(cells[14].inner_text().strip(), float)

                players_data[player_id] = batting_data
                
                if row_idx < 3:  # ì²« 3ê°œ í–‰ë§Œ ì¶œë ¥
                    sort_value = "N/A"
                    if current_header in ['BB', 'IBB', 'HBP', 'SO', 'GDP']:
                        sort_value = batting_data.get(current_header.lower(), "N/A")
                    elif current_header in ['SLG', 'OBP', 'OPS']:
                        sort_value = batting_data.get(current_header.lower(), "N/A")
                    elif current_header in ['MH', 'RISP', 'PH-BA']:
                        sort_value = batting_data.get('extra_stats', {}).get(current_header.lower().replace('-', '_'), "N/A")
                    
                    print(f"      âœ… {player_name} ({team_name}) - {current_header}: {sort_value}")
                
            except (ValueError, AttributeError) as e:
                print(f"      âš ï¸ {description} í–‰ íŒŒì‹± ì˜¤ë¥˜: {e}")
                continue

    except Exception as e:
        print(f"      âŒ {description} í…Œì´ë¸” íŒŒì‹± ì˜¤ë¥˜: {e}")

    return players_data


def _parse_basic2_header_data_fast(
    page: Page,
    current_header: str,
    description: str,
    year: int = 2025,
) -> Dict[int, Dict]:
    players_data: Dict[int, Dict] = {}
    team_mapping = get_team_mapping_for_year(year)

    rows_data = _extract_rows_fast(page)
    if not rows_data:
        return players_data

    thead = page.query_selector("thead")
    if thead:
        header_cells = thead.query_selector_all("th")
        headers = [cell.inner_text().strip() for cell in header_cells]
        print(f"      ğŸ” {description} ê¸°ì¤€ í…Œì´ë¸” í—¤ë”: {headers}")

    if rows_data:
        first_row = rows_data[0]
        cells = first_row.get("cells") or []
        print(f"      ğŸ” {description} ê¸°ì¤€ ì²« í–‰ ë°ì´í„° ({len(cells)}ê°œ ì»¬ëŸ¼):")
        for idx, value in enumerate(cells[:10]):
            print(f"         [{idx}]: '{value}'")

    for row in rows_data:
        cells = row.get("cells") or []
        if len(cells) < 5:
            continue

        href = row.get("linkHref")
        player_id = _extract_player_id_from_href(href)
        if not player_id:
            continue

        player_name = (row.get("linkText") or (cells[1] if len(cells) > 1 else "")).strip()
        team_name = cells[2] if len(cells) > 2 else ""
        team_code = get_team_code(team_name, year)
        if not team_code:
            team_code = team_mapping.get(team_name, team_name)

        batting_data = {
            "player_id": player_id,
            "player_name": player_name,
            "team_code": team_code,
        }

        if current_header == "BB" and len(cells) > 4:
            batting_data["walks"] = safe_parse_number(cells[4].strip(), int)
        elif current_header == "IBB" and len(cells) > 5:
            batting_data["intentional_walks"] = safe_parse_number(cells[5].strip(), int)
        elif current_header == "HBP" and len(cells) > 6:
            batting_data["hbp"] = safe_parse_number(cells[6].strip(), int)
        elif current_header == "SO" and len(cells) > 7:
            batting_data["strikeouts"] = safe_parse_number(cells[7].strip(), int)
        elif current_header == "GDP" and len(cells) > 8:
            batting_data["gdp"] = safe_parse_number(cells[8].strip(), int)
        elif current_header == "SLG" and len(cells) > 9:
            batting_data["slg"] = safe_parse_number(cells[9].strip(), float)
        elif current_header == "OBP" and len(cells) > 10:
            batting_data["obp"] = safe_parse_number(cells[10].strip(), float)
        elif current_header == "OPS" and len(cells) > 11:
            batting_data["ops"] = safe_parse_number(cells[11].strip(), float)
        elif current_header == "MH" and len(cells) > 12:
            batting_data.setdefault("extra_stats", {})
            batting_data["extra_stats"]["multi_hits"] = safe_parse_number(cells[12].strip(), int)
        elif current_header == "RISP" and len(cells) > 13:
            batting_data.setdefault("extra_stats", {})
            batting_data["extra_stats"]["risp_avg"] = safe_parse_number(cells[13].strip(), float)
        elif current_header == "PH-BA" and len(cells) > 14:
            batting_data.setdefault("extra_stats", {})
            batting_data["extra_stats"]["pinch_hit_avg"] = safe_parse_number(cells[14].strip(), float)

        players_data[player_id] = batting_data

    return players_data


def parse_basic2_header_data(
    page: Page,
    current_header: str,
    description: str,
    year: int = 2025,
    use_fast: Optional[bool] = None,
) -> Dict[int, Dict]:
    if use_fast is None:
        use_fast = os.getenv("KBO_FAST_PARSE", "1") != "0"
    if use_fast:
        return _parse_basic2_header_data_fast(page, current_header, description, year)
    return _parse_basic2_header_data_legacy(page, current_header, description, year)




def crawl_series_batting_stats(year: int = 2025, series_key: str = 'regular', 
                             limit: int = None, save_to_db: bool = False, 
                             headless: bool = False) -> List[Dict]:
    """
    íŠ¹ì • ì‹œë¦¬ì¦ˆì˜ íƒ€ì ê¸°ë¡ì„ í¬ë¡¤ë§
    
    Args:
        year: ì‹œì¦Œ ì—°ë„
        series_key: ì‹œë¦¬ì¦ˆ í‚¤ (regular, exhibition, wildcard, etc.)
        limit: ìˆ˜ì§‘í•  ì„ ìˆ˜ ìˆ˜ ì œí•œ
        save_to_db: DBì— ì €ì¥í• ì§€ ì—¬ë¶€
    
    Returns:
        ìˆ˜ì§‘ëœ íƒ€ì ê¸°ë¡ ë¦¬ìŠ¤íŠ¸
    """
    series_mapping = get_series_mapping()
    
    if series_key not in series_mapping:
        print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‹œë¦¬ì¦ˆ: {series_key}")
        return []
    
    series_info = series_mapping[series_key]
    all_players_data = []
    
    with sync_playwright() as playwright:
        browser = playwright.chromium.launch(headless=headless)
        page = browser.new_page()
        page.set_default_timeout(30000)
        install_sync_resource_blocking(page)

        try:
            print(f"\nğŸ“Š {year}ë…„ {series_info['name']} íƒ€ì ê¸°ë¡ ìˆ˜ì§‘ ì‹œì‘")
            print("-" * 60)

            # í˜ì´ì§€ë¡œ ì´ë™ (Basic1 ì‚¬ìš©)
            url = "https://www.koreabaseball.com/Record/Player/HitterBasic/Basic1.aspx"
            page.goto(url, wait_until='load', timeout=30000)
            page.wait_for_load_state('networkidle', timeout=30000)
            time.sleep(2)

            # ì‹œì¦Œê³¼ ì‹œë¦¬ì¦ˆ ì„¤ì •
            try:
                # ì‹œì¦Œ ì—°ë„ ì„ íƒ
                season_selector = 'select[name="ctl00$ctl00$ctl00$cphContents$cphContents$cphContents$ddlSeason$ddlSeason"]'
                page.select_option(season_selector, str(year))
                print(f"âœ… {year}ë…„ ì‹œì¦Œ ì„ íƒ")
                time.sleep(1)

                # ì‹œë¦¬ì¦ˆ ì„ íƒ
                series_selector = 'select[name="ctl00$ctl00$ctl00$cphContents$cphContents$cphContents$ddlSeries$ddlSeries"]'
                
                # ì‹œë¦¬ì¦ˆ ì˜µì…˜ë“¤ í™•ì¸ (ë””ë²„ê¹…)
                series_options = page.query_selector_all(f'{series_selector} option')
                print(f"ğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œë¦¬ì¦ˆ ì˜µì…˜:")
                for option in series_options:
                    value = option.get_attribute('value')
                    text = option.inner_text().strip()
                    print(f"   ê°’: '{value}' - í…ìŠ¤íŠ¸: '{text}'")
                
                page.select_option(series_selector, value=series_info['value'])
                print(f"âœ… {series_info['name']} ì„ íƒ")
                time.sleep(1)

                # íƒ€ì„(PA) ê¸°ì¤€ ì •ë ¬
                pa_sort_link = 'a[href="javascript:sort(\'PA_CN\');"]'
                if page.query_selector(pa_sort_link):
                    page.click(pa_sort_link)
                    print(f"âœ… íƒ€ì„(PA) ê¸°ì¤€ ì •ë ¬ ì ìš©")
                    page.wait_for_load_state('networkidle', timeout=30000)
                    time.sleep(2)
                else:
                    print("âš ï¸ íƒ€ì„ ì •ë ¬ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            except Exception as e:
                print(f"âš ï¸ í˜ì´ì§€ ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")

            # í˜ì´ì§• ì²˜ë¦¬í•˜ì—¬ ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘
            page_num = 1
            total_collected = 0
            
            while True:
                print(f"ğŸ“„ {page_num}í˜ì´ì§€ ìˆ˜ì§‘ ì¤‘...")
                
                # í˜„ì¬ í˜ì´ì§€ ë°ì´í„° íŒŒì‹±
                page_data = parse_batting_stats_table(page, series_key, year)
                
                if not page_data:
                    if page_num == 1:
                        print(f"âš ï¸ {series_info['name']}ì—ì„œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        print(f"ğŸ“„ {page_num}í˜ì´ì§€ì—ì„œ ë°ì´í„° ì—†ìŒ. í˜ì´ì§• ì¢…ë£Œ.")
                    break
                
                # ì‹œì¦Œ ì •ë³´ ì¶”ê°€
                for player_data in page_data:
                    player_data.update({
                        'season': year,
                        'league': series_info['league'],
                        'level': 'KBO1',
                        'source': 'CRAWLER'
                    })
                
                all_players_data.extend(page_data)
                total_collected += len(page_data)
                
                print(f"   âœ… {page_num}í˜ì´ì§€ì—ì„œ {len(page_data)}ëª… ìˆ˜ì§‘ (ëˆ„ì : {total_collected}ëª…)")
                
                # ì œí•œ ìˆ˜ í™•ì¸
                if limit and total_collected >= limit:
                    print(f"ğŸ¯ ëª©í‘œ ìˆ˜({limit}ëª…) ë‹¬ì„±. ìˆ˜ì§‘ ì¤‘ë‹¨.")
                    all_players_data = all_players_data[:limit]
                    break
                
                # í˜ì´ì§• êµ¬ì¡° ë””ë²„ê¹… (ì²« ë²ˆì§¸ í˜ì´ì§€ì—ì„œë§Œ)
                if page_num == 1:
                    print("ğŸ” í˜ì´ì§• êµ¬ì¡° ë””ë²„ê¹…:")
                    # í˜ì´ì§• ê´€ë ¨ ìš”ì†Œë“¤ ì°¾ê¸°
                    pager_elements = page.query_selector_all("*[class*='pag'], *[id*='pag'], *[class*='Pag'], a[href*='Page'], a[onclick*='Page']")
                    for i, elem in enumerate(pager_elements[:10]):  # ì²˜ìŒ 10ê°œë§Œ
                        try:
                            tag_name = elem.evaluate("el => el.tagName")
                            class_name = elem.get_attribute("class") or ""
                            href = elem.get_attribute("href") or ""
                            onclick = elem.get_attribute("onclick") or ""
                            text = elem.inner_text().strip() or ""
                            print(f"   [{i}] {tag_name}: class='{class_name}', href='{href}', onclick='{onclick}', text='{text}'")
                        except:
                            pass
                
                # ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™
                if not go_to_next_page(page, page_num):
                    print(f"ğŸ“„ ë§ˆì§€ë§‰ í˜ì´ì§€ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
                    break
                
                page_num += 1
                time.sleep(1)  # ì„œë²„ ë¶€í•˜ ë°©ì§€

            # ì •ê·œì‹œì¦Œì¸ ê²½ìš° Basic2 í˜ì´ì§€ì—ì„œ ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘
            if series_key == 'regular' and all_players_data:
                print(f"\nğŸ” ì •ê·œì‹œì¦Œ Basic2 ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
                basic2_data = crawl_basic2_with_headers(page, year, series_info)
                
                # Basic1ê³¼ Basic2 ë°ì´í„° ë³‘í•©
                if basic2_data:
                    basic1_dict = {p['player_id']: p for p in all_players_data}
                    
                    for player_id, basic2_player in basic2_data.items():
                        if player_id in basic1_dict:
                            # Basic1 ë°ì´í„°ì— Basic2 ë°ì´í„° ë³‘í•©
                            for key, value in basic2_player.items():
                                if value is not None and key not in ['player_id', 'player_name', 'team_code', 'season', 'league', 'level', 'source']:
                                    basic1_dict[player_id][key] = value
                    
                    # ë¦¬ìŠ¤íŠ¸ë¡œ ë‹¤ì‹œ ë³€í™˜
                    all_players_data = list(basic1_dict.values())
                    print(f"âœ… Basic1 + Basic2 ë°ì´í„° ë³‘í•© ì™„ë£Œ")
                else:
                    print(f"âš ï¸ Basic2 ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨, Basic1 ë°ì´í„°ë§Œ ì‚¬ìš©")
            
            print(f"âœ… {series_info['name']} ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")

        except Exception as e:
            print(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {e}")
        
        finally:
            browser.close()

    print("-" * 60)
    print(f"âœ… {series_info['name']} í¬ë¡¤ë§ ì™„ë£Œ! ì´ {len(all_players_data)}ëª… ìˆ˜ì§‘")

    # DB ì €ì¥ (ì•ˆì „í•œ ì™¸ë˜í‚¤ ì œì•½ì¡°ê±´ ìš°íšŒ)
    if save_to_db and all_players_data:
        print(f"\nğŸ’¾ íƒ€ì ë°ì´í„° DB ì €ì¥ ì‹œì‘ (ì™¸ë˜í‚¤ ì œì•½ì¡°ê±´ ì„ì‹œ ë¹„í™œì„±í™”)...")
        try:
            saved_count = save_batting_stats_safe(all_players_data)
            print(f"âœ… íƒ€ì ë°ì´í„° ì €ì¥ ì™„ë£Œ: {saved_count}ëª…")
        except Exception as e:
            print(f"âŒ íƒ€ì ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")

    return all_players_data


def crawl_all_series(year: int = 2025, limit: int = None, save_to_db: bool = False, headless: bool = False) -> Dict[str, List[Dict]]:
    """
    ëª¨ë“  ì‹œë¦¬ì¦ˆì˜ íƒ€ì ê¸°ë¡ì„ í¬ë¡¤ë§
    
    Returns:
        ì‹œë¦¬ì¦ˆë³„ ìˆ˜ì§‘ëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
    """
    series_mapping = get_series_mapping()
    all_series_data = {}
    
    for series_key, series_info in series_mapping.items():
        print(f"\nğŸš€ {series_info['name']} ì‹œì‘...")
        series_data = crawl_series_batting_stats(year, series_key, limit, save_to_db, headless)
        all_series_data[series_key] = series_data
        
        # ì‹œë¦¬ì¦ˆ ê°„ ëŒ€ê¸°
        time.sleep(3)
    
    return all_series_data


def main():
    parser = argparse.ArgumentParser(description="KBO ì „ì²´ ì‹œë¦¬ì¦ˆ íƒ€ì ê¸°ë¡ í¬ë¡¤ëŸ¬")
    
    parser.add_argument("--year", type=int, default=2025, help="ì‹œì¦Œ ì—°ë„ (ê¸°ë³¸ê°’: 2025)")
    parser.add_argument("--series", type=str, help="íŠ¹ì • ì‹œë¦¬ì¦ˆë§Œ í¬ë¡¤ë§ (regular, exhibition, wildcard, etc.)")
    parser.add_argument("--limit", type=int, help="ìˆ˜ì§‘í•  ì„ ìˆ˜ ìˆ˜ ì œí•œ")
    parser.add_argument("--save", action="store_true", help="DBì— ì €ì¥")
    parser.add_argument("--headless", action="store_true", help="í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œë¡œ ì‹¤í–‰")
    
    args = parser.parse_args()

    if args.series:
        # íŠ¹ì • ì‹œë¦¬ì¦ˆë§Œ í¬ë¡¤ë§
        crawl_series_batting_stats(args.year, args.series, args.limit, args.save, args.headless)
    else:
        # ëª¨ë“  ì‹œë¦¬ì¦ˆ í¬ë¡¤ë§
        all_data = crawl_all_series(args.year, args.limit, args.save, args.headless)
        
        # ì „ì²´ ìš”ì•½
        print(f"\n" + "=" * 60)
        print(f"ğŸ“ˆ ì „ì²´ ìˆ˜ì§‘ ìš”ì•½ ({args.year}ë…„)")
        print("=" * 60)
        for series_key, data in all_data.items():
            series_name = get_series_mapping()[series_key]['name']
            print(f"  {series_name}: {len(data)}ëª…")
        
        total_players = sum(len(data) for data in all_data.values())
        print(f"\nì´ ìˆ˜ì§‘ ì„ ìˆ˜: {total_players}ëª…")


if __name__ == "__main__":
    main()
