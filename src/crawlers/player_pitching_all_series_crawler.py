"""
KBO ì „ì²´ ì‹œë¦¬ì¦ˆ íˆ¬ìˆ˜ ê¸°ë¡ í¬ë¡¤ëŸ¬

ìš”êµ¬ì‚¬í•­ ìš”ì•½:
1. https://www.koreabaseball.com/Record/Player/PitcherBasic/Basic1.aspx í˜ì´ì§€ì—ì„œ
   - ì‹œì¦Œ/ì‹œë¦¬ì¦ˆ ì„ íƒ í›„ `G`(ê²½ê¸°) í—¤ë”ë¥¼ í´ë¦­í•˜ì—¬ ì •ë ¬
   - ëª¨ë“  í˜ì´ì§€ë¥¼ ìˆœíšŒí•˜ë©° ì •ê·œì‹œì¦Œ íˆ¬ìˆ˜ ê¸°ë³¸ ê¸°ë¡ ìˆ˜ì§‘
2. https://www.koreabaseball.com/Record/Player/PitcherBasic/Basic2.aspx í˜ì´ì§€ì—ì„œ
   - `CG, SHO, QS, BSV, TBF, NP, AVG, 2B, 3B, SAC, SF, IBB, WP, BK` í—¤ë”ë¥¼ ìˆœì„œëŒ€ë¡œ í´ë¦­
   - ê° ì •ë ¬ë§ˆë‹¤ ì „ì²´ í˜ì´ì§€ë¥¼ ìˆœíšŒí•˜ë©° ì¶”ê°€ ì§€í‘œ ìˆ˜ì§‘ ë° ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸
3. Docs/schema/KBO_ì‹œì¦Œë³„ íˆ¬ìˆ˜ê¸°ë¡ í…Œì´ë¸”.csvì— ì •ì˜ëœ ìŠ¤í‚¤ë§ˆì— ë§ì¶° ë°ì´í„° ì •ë¦¬
4. í•„ìš” ì‹œ Supabase(PostgreSQL)ì— UPSERT ì €ì¥ (season_id + player_id ê¸°ì¤€)

Usage:
    python -m src.crawlers.pitching_stats_crawler --year 2025 --series regular --save --sync-supabase
"""
from __future__ import annotations

import argparse
import os
import re
import time
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple

from playwright.sync_api import sync_playwright, Page, TimeoutError as PlaywrightTimeout

from src.repositories.player_season_pitching_repository import save_pitching_stats_to_db
from src.utils.team_codes import resolve_team_code
from src.utils.playwright_blocking import install_sync_resource_blocking
from src.utils.request_policy import RequestPolicy
from src.utils.compliance import compliance




# ---------------------------------------------------------------------------
# Constants & configuration
# ---------------------------------------------------------------------------

BASIC1_URL = "https://www.koreabaseball.com/Record/Player/PitcherBasic/Basic1.aspx"
BASIC2_URL = "https://www.koreabaseball.com/Record/Player/PitcherBasic/Basic2.aspx"

BASIC1_SORT_CODE = "IP_CN"  # 'IP' (ì´ë‹) í—¤ë”

# ì •ê·œì‹œì¦Œ Basic2ì—ì„œëŠ” NP(íˆ¬êµ¬ìˆ˜)ë§Œ ìˆ˜ì§‘
BASIC2_SORT_SEQUENCE = [
    ("NP", "PIT_CN"),  # íˆ¬êµ¬ìˆ˜
]

SERIES_MAPPING: Dict[str, Dict[str, str]] = {
    "regular": {
        "name": "KBO ì •ê·œì‹œì¦Œ",
        "value": "0",
        "league": "REGULAR",
    },
    "exhibition": {
        "name": "KBO ì‹œë²”ê²½ê¸°",
        "value": "1",
        "league": "EXHIBITION",
    },
    "wildcard": {
        "name": "KBO ì™€ì¼ë“œì¹´ë“œ",
        "value": "4",
        "league": "WILDCARD",
    },
    "semi_playoff": {
        "name": "KBO ì¤€í”Œë ˆì´ì˜¤í”„",
        "value": "3",
        "league": "SEMI_PLAYOFF",
    },
    "playoff": {
        "name": "KBO í”Œë ˆì´ì˜¤í”„",
        "value": "5",
        "league": "PLAYOFF",
    },
    "korean_series": {
        "name": "KBO í•œêµ­ì‹œë¦¬ì¦ˆ",
        "value": "7",
        "league": "KOREAN_SERIES",
    },
}

PRIMARY_SORT_CONFIG = {
    "regular": {"label": "IP", "sort_code": "IP_CN"},
    "default": {"label": "IP", "sort_code": "IP_CN"},
}

# ---------------------------------------------------------------------------
# Helper utilities
# ---------------------------------------------------------------------------

def normalize_header(text: str) -> str:
    if text is None:
        return ""
    cleaned = text.replace('\xa0', ' ').strip()
    if '\n' in cleaned:
        cleaned = cleaned.split('\n')[0].strip()
    parts = cleaned.split()
    if len(parts) > 1:
        cleaned = parts[0]
    return cleaned


def safe_int(value: Optional[str]) -> Optional[int]:
    if value is None:
        return None
    cleaned = value.replace(",", "").strip()
    if cleaned in {"", "-", "â€“"}:
        return None
    try:
        return int(float(cleaned))
    except ValueError:
        return None


def safe_float(value: Optional[str]) -> Optional[float]:
    if value is None:
        return None
    cleaned = value.replace(",", "").strip()
    if cleaned in {"", "-", "â€“"}:
        return None
    try:
        return float(cleaned)
    except ValueError:
        return None


def parse_innings(value: Optional[str]) -> Tuple[Optional[float], Optional[int]]:
    """
    Convert inning string (e.g. '180 2/3') into (innings_float, outs_int).
    """
    if value is None:
        return None, None
    cleaned = value.replace(",", "").strip()
    if cleaned in {"", "-", "â€“"}:
        return None, None

    innings_float: Optional[float] = None
    outs: Optional[int] = None

    try:
        main_part = cleaned
        fraction_part = ""
        if " " in cleaned:
            main_part, fraction_part = cleaned.split()
        elif "/" in cleaned:
            main_part, fraction_part = "0", cleaned

        # main innings
        main_int = int(float(main_part))
        outs = main_int * 3

        frac_value = 0.0
        if fraction_part:
            if "/" in fraction_part:
                num, den = fraction_part.split("/")
                num_i, den_i = int(num), int(den)
                outs += int(round(num_i * 3 / den_i))
                frac_value = num_i / den_i
            else:
                # decimal form (rare)
                frac_value = float(fraction_part)
                outs += int(round(frac_value * 3))
        innings_float = main_int + frac_value

        # handle decimals without space (e.g., '12.1')
        if not fraction_part and "." in cleaned:
            innings_float = float(cleaned)
            fractional = innings_float - int(innings_float)
            if abs(fractional - 0.1) < 0.05:
                outs = int(innings_float) * 3 + 1
            elif abs(fractional - 0.2) < 0.05:
                outs = int(innings_float) * 3 + 2
            else:
                outs = int(round(innings_float * 3))

        return round(innings_float, 2) if innings_float is not None else None, outs
    except (ValueError, ZeroDivisionError):
        return None, None


def extract_player_id(href: Optional[str]) -> Optional[int]:
    if not href:
        return None
    match = re.search(r"playerId=(\d+)", href)
    return int(match.group(1)) if match else None


def _extract_rows_fast(page: Page, table_selector: str = "table.tData01.tt") -> Optional[List[Dict[str, object]]]:
    try:
        payload = page.evaluate(
            """
            (selector) => {
                const table = document.querySelector(selector);
                if (!table) return null;
                const body = table.tBodies && table.tBodies.length ? table.tBodies[0] : table;
                const rows = Array.from(body.querySelectorAll('tr'));
                return rows.map((row) => {
                    const cells = Array.from(row.querySelectorAll('td')).map(td => (td.innerText || '').trim());
                    const link = row.querySelector('a');
                    return {
                        cells,
                        linkText: link ? (link.innerText || '').trim() : null,
                        linkHref: link ? link.getAttribute('href') : null,
                    };
                });
            }
            """,
            table_selector,
        )
        return payload or []
    except Exception:
        return None


def wait_for_table(page: Page, timeout: int = 30000) -> None:
    try:
        page.wait_for_selector(
            "table.tData01.tt tbody tr",
            timeout=timeout,
            state="attached",
        )
    except PlaywrightTimeout:
        print("   âš ï¸  í…Œì´ë¸” í–‰ì´ í‘œì‹œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ë°ì´í„° ì—†ìŒ ê°€ëŠ¥ì„±)")
    finally:
        page.wait_for_timeout(500)


def go_to_next_page(page: Page, current_page: int) -> bool:
    """
    ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™ (1â†’2,3,4,5â†’ë‹¤ìŒâ†’6,7,8,9,10â†’ë‹¤ìŒ ë°˜ë³µ)
    íƒ€ì í¬ë¡¤ëŸ¬ì™€ ë™ì¼í•œ ê°œì„ ëœ ë¡œì§
    """
    try:
        # 1â†’2,3,4,5â†’ë‹¤ìŒâ†’6,7,8,9,10â†’ë‹¤ìŒ íŒ¨í„´
        if current_page % 5 == 0:  # 5í˜ì´ì§€ë§ˆë‹¤ "ë‹¤ìŒ" ë²„íŠ¼ í´ë¦­
            # ë‹¤ìŒ ë²„íŠ¼ ì°¾ê¸°
            next_button_selector = 'a[href*="btnNext"]'
            next_button = page.query_selector(next_button_selector)
            
            if not next_button:
                print("   ğŸ“„ ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # ë²„íŠ¼ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            disabled_attr = next_button.get_attribute("disabled")
            class_attr = next_button.get_attribute("class") or ""
            if disabled_attr or "disabled" in class_attr:
                print("   ğŸ“„ ë§ˆì§€ë§‰ í˜ì´ì§€ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
                return False
            
            print(f"   â¡ï¸ ë‹¤ìŒ ë²„íŠ¼ í´ë¦­ ({current_page}í˜ì´ì§€ í›„)")
            next_button.click()
            page.wait_for_load_state('networkidle', timeout=30000)
            page.wait_for_timeout(2000)  # 2ì´ˆ ëŒ€ê¸°
            
        else:
            # 5í˜ì´ì§€ ë‚´ì—ì„œ ë²ˆí˜¸ ë²„íŠ¼ í´ë¦­
            next_page = current_page + 1
            relative = ((next_page - 1) % 5) + 1
            selector = f'a[href*="btnNo{relative}"]'
            page_button = page.query_selector(selector)
            
            if not page_button:
                print(f"   ğŸ“„ {relative}ë²ˆ í˜ì´ì§€ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            print(f"   â¡ï¸ {relative}ë²ˆ í˜ì´ì§€ ë²„íŠ¼ í´ë¦­")
            page_button.click()
            page.wait_for_load_state("networkidle", timeout=30000)
            page.wait_for_timeout(1000)  # 1ì´ˆ ëŒ€ê¸°
        
        # í˜ì´ì§€ ì´ë™ í›„ í…Œì´ë¸” ëŒ€ê¸°
        wait_for_table(page)
        return True
        
    except PlaywrightTimeout as e:
        print(f"   âš ï¸ í˜ì´ì§€ ì´ë™ ì¤‘ íƒ€ì„ì•„ì›ƒ: {e}")
        return False
    except Exception as e:
        print(f"   âš ï¸ í˜ì´ì§€ ì´ë™ ì¤‘ ì˜¤ë¥˜: {e}")
        return False


def apply_sort(page: Page, header_label: str, sort_code: Optional[str] = None) -> bool:
    if sort_code:
        selector = f"a[href=\"javascript:sort('{sort_code}');\"]"
        anchor = page.query_selector(selector)
        if anchor:
            anchor.click()
            page.wait_for_load_state("networkidle", timeout=60000)
            page.wait_for_timeout(800)
            return True

    anchors = page.query_selector_all("table.tData01.tt thead a")
    for anchor in anchors:
        label = normalize_header(anchor.inner_text())
        if label == header_label:
            anchor.click()
            page.wait_for_load_state("networkidle", timeout=60000)
            page.wait_for_timeout(800)
            return True

    print(f"âš ï¸  '{header_label}' ì •ë ¬ ë§í¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    return False


# ---------------------------------------------------------------------------
# Data structures
# ---------------------------------------------------------------------------

@dataclass
class PitcherStats:
    player_id: int
    season: int
    league: str
    level: str = "KBO1"
    source: str = "CRAWLER"
    player_name: Optional[str] = None
    team_name: Optional[str] = None
    team_code: Optional[str] = None
    games: Optional[int] = None
    games_started: Optional[int] = None
    wins: Optional[int] = None
    losses: Optional[int] = None
    saves: Optional[int] = None
    holds: Optional[int] = None
    innings_pitched: Optional[float] = None
    innings_outs: Optional[int] = None
    hits_allowed: Optional[int] = None
    runs_allowed: Optional[int] = None
    earned_runs: Optional[int] = None
    home_runs_allowed: Optional[int] = None
    walks_allowed: Optional[int] = None
    intentional_walks: Optional[int] = None
    hit_batters: Optional[int] = None
    strikeouts: Optional[int] = None
    wild_pitches: Optional[int] = None
    balks: Optional[int] = None
    era: Optional[float] = None
    whip: Optional[float] = None
    fip: Optional[float] = None
    k_per_nine: Optional[float] = None
    bb_per_nine: Optional[float] = None
    kbb: Optional[float] = None
    extra_stats: Dict[str, object] = field(default_factory=lambda: {"rankings": {}})

    def to_repository_payload(self) -> Dict[str, Optional[object]]:
        """íƒ€ì í¬ë¡¤ëŸ¬ ë°©ì‹ì˜ ë‹¨ìˆœ ë°ì´í„° êµ¬ì¡°"""
        data = {
            "player_id": self.player_id,
            "season": self.season,
            "league": self.league,
            "level": self.level,
            "source": self.source,
            "team_code": self.team_code,
            # íˆ¬ìˆ˜ ê¸°ë³¸ ìŠ¤íƒ¯
            "games": self.games,
            "games_started": self.games_started, 
            "wins": self.wins,
            "losses": self.losses,
            "saves": self.saves,
            "holds": self.holds,
            "innings_pitched": self.innings_pitched,  # íƒ€ìì²˜ëŸ¼ ë‹¨ìˆœ í•„ë“œëª…
            "hits_allowed": self.hits_allowed,
            "runs_allowed": self.runs_allowed,
            "earned_runs": self.earned_runs,
            "home_runs_allowed": self.home_runs_allowed,
            "walks_allowed": self.walks_allowed,
            "intentional_walks": self.intentional_walks,
            "hit_batters": self.hit_batters,
            "strikeouts": self.strikeouts,
            "wild_pitches": self.wild_pitches,
            "balks": self.balks,
            "era": self.era,
            "whip": self.whip,
            "extra_stats": self.extra_stats,
        }
        # innings_outsë¥¼ extra_statsì— ë”°ë¡œ ì €ì¥
        if self.innings_outs is not None:
            data.setdefault("extra_stats", {})
            if isinstance(data["extra_stats"], dict):
                data["extra_stats"]["innings_outs"] = self.innings_outs
        return data


# ---------------------------------------------------------------------------
# Parsing helpers
# ---------------------------------------------------------------------------

def parse_basic1_page(
    page: Page,
    season: int,
    league: str,
    pitchers: Dict[int, PitcherStats],
    max_players: Optional[int] = None,
) -> int:
    headers = [normalize_header(th.inner_text()) for th in page.query_selector_all("table.tData01.tt thead th")]
    header_index = {name: idx for idx, name in enumerate(headers)}
    team_mapping = get_team_mapping_for_year(season)
    use_fast = os.getenv("KBO_FAST_PARSE", "1") != "0"

    core_headers = ["ì„ ìˆ˜ëª…", "íŒ€ëª…", "IP", "G", "ERA"]
    missing_core = [h for h in core_headers if h not in header_index]
    if missing_core:
        print(f"âš ï¸  Basic1 í…Œì´ë¸” í—¤ë”ì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing_core)}")
        print("   í—¤ë” ëª©ë¡:", headers)
        return 0

    rows_data = _extract_rows_fast(page) if use_fast else None
    rows = rows_data if rows_data is not None else page.query_selector_all("table.tData01.tt tbody tr")
    processed = 0

    for row in rows:
        if rows_data is not None:
            cells = row.get("cells") or []
            if len(cells) < len(headers):
                continue
    """
    Basic1 Page Parsing with JS Fast Path
    """
    
    # JavaScript Payload Extraction
    extraction_script = """
    () => {
        const rows = document.querySelectorAll('table.tData01.tt tbody tr');
        if (rows.length === 0) return [];
        
        const headers = Array.from(document.querySelectorAll('table.tData01.tt thead th')).map(th => th.innerText.trim());
        const headerIndex = {};
        headers.forEach((h, i) => headerIndex[h] = i);
        
        const results = [];
        
        rows.forEach(row => {
            const cells = Array.from(row.querySelectorAll('td'));
            if (cells.length < headers.length) return;
            
            // Player Info (Assuming "ì„ ìˆ˜ëª…" is present)
            let nameIndex = headerIndex["ì„ ìˆ˜ëª…"];
            if (nameIndex === undefined) return;
            
            const nameCell = cells[nameIndex];
            const link = nameCell.querySelector('a');
            if (!link) return; // Should have link
            
            const href = link.getAttribute('href');
            const idMatch = href.match(/playerId=(\\d+)/);
            if (!idMatch) return;
            
            const player_id = parseInt(idMatch[1]);
            const player_name = link.innerText.trim();
            const team_name = cells[headerIndex["íŒ€ëª…"]].innerText.trim();
            
            // Extract raw text for mapping in Python
            const raw = {};
            for (const [key, idx] of Object.entries(headerIndex)) {
                raw[key] = cells[idx].innerText.trim();
            }
            
            results.push({ player_id, player_name, team_name, raw });
        });
        return results;
    }
    """

    try:
        extracted_rows = page.evaluate(extraction_script)
        team_mapping = get_team_mapping_for_year(season)
        processed = 0

        for row in extracted_rows:
            player_id = row['player_id']
            
            if max_players and player_id not in pitchers and len(pitchers) >= max_players:
                continue
            
            player_name = row['player_name']
            team_name = row['team_name']
            raw = row['raw']
            
            # Map Team Code
            team_code = resolve_team_code(team_name, season) or team_name

            stats = pitchers.get(player_id)
            if not stats:
                stats = PitcherStats(
                    player_id=player_id,
                    season=season,
                    league=league,
                )
                pitchers[player_id] = stats
            
            stats.player_name = player_name
            stats.team_name = team_name
            stats.team_code = team_code
            
            # Helper to get raw value safely
            def get_val(key): return raw.get(key)

            stats.games = safe_int(get_val("G")) if "G" in raw else stats.games
            stats.wins = safe_int(get_val("W")) if "W" in raw else stats.wins
            stats.losses = safe_int(get_val("L")) if "L" in raw else stats.losses
            stats.saves = safe_int(get_val("SV")) if "SV" in raw else stats.saves
            stats.holds = safe_int(get_val("HLD")) if "HLD" in raw else stats.holds
            
            if "IP" in raw:
                ip_value, outs_value = parse_innings(get_val("IP"))
                stats.innings_pitched = ip_value
                stats.innings_outs = outs_value

            stats.hits_allowed = safe_int(get_val("H")) if "H" in raw else stats.hits_allowed
            stats.home_runs_allowed = safe_int(get_val("HR")) if "HR" in raw else stats.home_runs_allowed
            stats.walks_allowed = safe_int(get_val("BB")) if "BB" in raw else stats.walks_allowed
            stats.hit_batters = safe_int(get_val("HBP")) if "HBP" in raw else stats.hit_batters
            stats.strikeouts = safe_int(get_val("SO")) if "SO" in raw else stats.strikeouts
            stats.runs_allowed = safe_int(get_val("R")) if "R" in raw else stats.runs_allowed
            stats.earned_runs = safe_int(get_val("ER")) if "ER" in raw else stats.earned_runs
            stats.era = safe_float(get_val("ERA")) if "ERA" in raw else stats.era
            stats.whip = safe_float(get_val("WHIP")) if "WHIP" in raw else stats.whip

            # Extra metrics
            metrics = stats.extra_stats.setdefault("metrics", {})
            
            for header, key in [
                ("CG", "complete_games"), ("SHO", "shutouts"), ("TBF", "tbf"),
            ]:
                if header in raw:
                    val = safe_int(get_val(header))
                    if val is not None: metrics[key] = val
            
            rank_value = safe_int(get_val("ìˆœìœ„")) if "ìˆœìœ„" in raw else None
            win_pct = safe_float(get_val("WPCT")) if "WPCT" in raw else None
            
            rankings = stats.extra_stats.setdefault("rankings", {})
            rankings["basic1"] = rank_value
            if stats.era is not None: metrics["era"] = stats.era
            if win_pct is not None: metrics["win_pct"] = win_pct
            
            processed += 1
            
        return processed
        
    except Exception as e:
        print(f"âŒ Basic1 íŒŒì‹± ì˜¤ë¥˜ (JS): {e}")
        return 0


def parse_basic2_page(
    page: Page,
    season: int,
    league: str,
    pitchers: Dict[int, PitcherStats],
    sort_key: str,
    max_players: Optional[int] = None,
) -> int:
    headers = [normalize_header(th.inner_text()) for th in page.query_selector_all("table.tData01.tt thead th")]
    header_index = {name: idx for idx, name in enumerate(headers)}
    team_mapping = get_team_mapping_for_year(season)
    use_fast = os.getenv("KBO_FAST_PARSE", "1") != "0"

    # Basic2 í—¤ë”ëŠ” ì •ê·œì‹œì¦Œê³¼ í¬ìŠ¤íŠ¸ì‹œì¦Œì—ì„œ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
    if "ì„ ìˆ˜ëª…" not in header_index or "íŒ€ëª…" not in header_index:
        print("âš ï¸  Basic2 í…Œì´ë¸” í—¤ë” íŒŒì‹± ì‹¤íŒ¨")
        return 0

    rows_data = _extract_rows_fast(page) if use_fast else None
    rows = rows_data if rows_data is not None else page.query_selector_all("table.tData01.tt tbody tr")
    processed = 0

    for row in rows:
        if rows_data is not None:
            cells = row.get("cells") or []
            if len(cells) < len(headers):
                continue
            link_href = row.get("linkHref")
            player_id = extract_player_id(link_href)
            if not player_id:
                continue

            def cell_text(idx: int) -> Optional[str]:
                return cells[idx] if len(cells) > idx else None

            player_name = (row.get("linkText") or cell_text(header_index["ì„ ìˆ˜ëª…"]) or "").strip()
            team_name = (cell_text(header_index["íŒ€ëª…"]) or "").strip()
        else:
            cells = row.query_selector_all("td")
            if len(cells) < len(headers):
                continue

            def cell_text(idx: int) -> Optional[str]:
                return cells[idx].inner_text() if len(cells) > idx else None

            link = cells[header_index["ì„ ìˆ˜ëª…"]].query_selector("a")
            player_id = extract_player_id(link.get_attribute("href") if link else None)
            if not player_id:
                continue
            player_name = link.inner_text().strip() if link else cells[header_index["ì„ ìˆ˜ëª…"]].inner_text().strip()
            team_name = cells[header_index["íŒ€ëª…"]].inner_text().strip()

        if max_players and player_id not in pitchers and len(pitchers) >= max_players:
            continue

        stats = pitchers.get(player_id)
        if not stats:
            stats = PitcherStats(player_id=player_id, season=season, league=league)
            pitchers[player_id] = stats
            stats.player_name = player_name
            stats.team_name = team_name
            team_code = resolve_team_code(team_name, season) or team_name
            stats.team_code = team_code

        metrics = stats.extra_stats.setdefault("metrics", {})

        def set_metric(header_name: str, key: str, caster):
            if header_name in header_index:
                value = caster(cell_text(header_index[header_name]))
                if value is not None:
                    metrics[key] = value

        set_metric("CG", "complete_games", safe_int)
        set_metric("SHO", "shutouts", safe_int)
        set_metric("QS", "quality_starts", safe_int)
        set_metric("BSV", "blown_saves", safe_int)
        set_metric("TBF", "tbf", safe_int)
        set_metric("NP", "np", safe_int)
        set_metric("AVG", "avg_against", safe_float)
        set_metric("2B", "doubles_allowed", safe_int)
        set_metric("3B", "triples_allowed", safe_int)
        set_metric("SAC", "sacrifices_allowed", safe_int)
        set_metric("SF", "sacrifice_flies_allowed", safe_int)

        if "IBB" in header_index:
            val = safe_int(cell_text(header_index["IBB"]))
            if val is not None:
                stats.intentional_walks = val
        if "WP" in header_index:
            val = safe_int(cell_text(header_index["WP"]))
            if val is not None:
                stats.wild_pitches = val
        if "BK" in header_index:
            val = safe_int(cell_text(header_index["BK"]))
            if val is not None:
                stats.balks = val

        # ë­í‚¹ ê¸°ë¡
        rank_val = safe_int(cell_text(header_index.get("ìˆœìœ„", 0))) if "ìˆœìœ„" in header_index else None
        if rank_val is not None:
            rankings = stats.extra_stats.setdefault("rankings", {})
            rankings[sort_key] = rank_val

        processed += 1

    return processed


# ---------------------------------------------------------------------------
# Crawling logic
# ---------------------------------------------------------------------------

def setup_pitcher_page(page: Page, url: str, year: int, series_value: str, policy: Optional[RequestPolicy] = None) -> bool:
    if policy:
        policy.delay(host="www.koreabaseball.com")
    
    if not compliance.is_allowed_sync(url):
        print(f"[COMPLIANCE] Navigation to {url} aborted.")
        return False

    page.goto(url, wait_until="load", timeout=60000)
    page.wait_for_load_state("networkidle", timeout=60000)
    page.wait_for_timeout(1000)

    try:
        season_selector = 'select[name="ctl00$ctl00$ctl00$cphContents$cphContents$cphContents$ddlSeason$ddlSeason"]'
        series_selector = 'select[name="ctl00$ctl00$ctl00$cphContents$cphContents$cphContents$ddlSeries$ddlSeries"]'
        page.select_option(season_selector, str(year))
        page.wait_for_timeout(300)
        page.select_option(series_selector, value=series_value)
        page.wait_for_timeout(500)
        page.wait_for_load_state("networkidle", timeout=60000)
        page.wait_for_timeout(500)
        return True
    except PlaywrightTimeout:
        return False


def crawl_pitcher_series(
    year: int,
    series_key: str,
    limit: Optional[int] = None,
    headless: bool = True,
    save_to_db: bool = False,
) -> List[PitcherStats]:
    if series_key not in SERIES_MAPPING:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‹œë¦¬ì¦ˆ í‚¤: {series_key}")

    series_info = SERIES_MAPPING[series_key]
    league_name = series_info.get("league", "REGULAR")
    print(f"\nğŸ“Š {year}ë…„ {series_info['name']} ìˆ˜ì§‘ ì‹œì‘")

    policy = RequestPolicy()

    with sync_playwright() as playwright:
        browser = playwright.chromium.launch(headless=headless)
        # Apply UA rotation via context
        context = browser.new_context(**policy.build_context_kwargs(locale='ko-KR'))
        page = context.new_page()
        page.set_default_timeout(60000)
        install_sync_resource_blocking(page)

        # Step 1: Basic1 - ì‹œë¦¬ì¦ˆë³„ ì •ë ¬ í›„ ì „ì²´ í˜ì´ì§€ ìˆ˜ì§‘
        if not setup_pitcher_page(page, BASIC1_URL, year, series_info["value"], policy=policy):
            print("âŒ Basic1 í˜ì´ì§€ ì„¤ì • ì‹¤íŒ¨")
            browser.close()
            return []

        primary_sort = PRIMARY_SORT_CONFIG.get(
            series_key, PRIMARY_SORT_CONFIG["default"]
        )
        apply_sort(
            page,
            header_label=primary_sort["label"],
            sort_code=primary_sort["sort_code"],
        )

        wait_for_table(page)

        page_number = 1
        while True:
            parsed = parse_basic1_page(
                page,
                season=year,
                league=league_name,
                pitchers=pitchers,
                max_players=limit,
            )
            print(f"   â–¶ Basic1 {page_number}í˜ì´ì§€: {parsed}ëª… ì²˜ë¦¬ (ëˆ„ì  {len(pitchers)}ëª…)")

            if limit and len(pitchers) >= limit:
                print("   ğŸ¯ ìˆ˜ì§‘ ì œí•œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
                break

            if not go_to_next_page(page, page_number):
                break
            page_number += 1

        print(f"âœ… Basic1 ìˆ˜ì§‘ ì™„ë£Œ: ì´ {len(pitchers)}ëª…")

        # Step 2: Basic2 (ì •ê·œì‹œì¦Œë§Œ ì‹¤í–‰)
        if series_key == "regular":
            if not setup_pitcher_page(page, BASIC2_URL, year, series_info["value"], policy=policy):
                print("âš ï¸  Basic2 í˜ì´ì§€ ì„¤ì • ì‹¤íŒ¨. ì¶”ê°€ ì§€í‘œ ì—†ì´ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                browser.close()
                return list(pitchers.values()) if not limit else list(pitchers.values())[:limit]

            for display_name, sort_code in BASIC2_SORT_SEQUENCE:
                if not apply_sort(page, display_name, sort_code):
                    continue
                wait_for_table(page)

                page_number = 1
                total_processed = 0

                while True:
                    processed = parse_basic2_page(
                        page,
                        season=year,
                        league=league_name,
                        pitchers=pitchers,
                        sort_key=display_name,
                        max_players=limit,
                    )
                    total_processed += processed

                    if not go_to_next_page(page, page_number):
                        break
                    page_number += 1

                print(f"   âœ… Basic2 {display_name} ì •ë ¬ ì²˜ë¦¬: {total_processed}í–‰")

        browser.close()

    stats_list = list(pitchers.values())
    if limit:
        stats_list = stats_list[:limit]

    print(f"âœ… {series_info['name']} í¬ë¡¤ë§ ì™„ë£Œ: {len(stats_list)}ëª…")

    # íˆ¬ìˆ˜ ì „ìš© í…Œì´ë¸”ì— ì €ì¥
    if save_to_db and stats_list:
        print(f"\nğŸ’¾ íˆ¬ìˆ˜ ë°ì´í„° ì €ì¥ ì‹œì‘ (player_season_pitching í…Œì´ë¸”)...")
        try:
            payloads = [stat.to_repository_payload() for stat in stats_list]
            saved_count = save_pitching_stats_to_db(payloads)
            print(f"âœ… íˆ¬ìˆ˜ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {saved_count}ëª…")
            print(f"ğŸ“Œ ë‹¤ìŒ ë‹¨ê³„: ./venv/bin/python3 src/sync/supabase_sync.py ì‹¤í–‰í•˜ì—¬ Supabase ë™ê¸°í™”")
        except Exception as e:
            print(f"âŒ íˆ¬ìˆ˜ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")

    return stats_list


# ---------------------------------------------------------------------------
# CLI
# ---------------------------------------------------------------------------

def parse_arguments() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="KBO íˆ¬ìˆ˜ ê¸°ë¡ í¬ë¡¤ëŸ¬ (Basic1/Basic2)")
    parser.add_argument("--year", type=int, default=2025, help="ì‹œì¦Œ ì—°ë„ (ê¸°ë³¸: 2025)")
    parser.add_argument(
        "--series",
        type=str,
        choices=list(SERIES_MAPPING.keys()),
        help="íŠ¹ì • ì‹œë¦¬ì¦ˆë§Œ ìˆ˜ì§‘ (ê¸°ë³¸ê°’: ì „ì²´ ì‹œë¦¬ì¦ˆ)",
    )
    parser.add_argument("--limit", type=int, help="ìˆ˜ì§‘í•  ì„ ìˆ˜ ìˆ˜ ì œí•œ (ë””ë²„ê¹…ìš©)")
    parser.add_argument("--headless", action="store_true", help="í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ ì‚¬ìš©")
    parser.add_argument(
        "--save",
        action="store_true",
        help="DBì— ì €ì¥",
    )
    return parser.parse_args()


def main():
    args = parse_arguments()

    if args.series:
        # íŠ¹ì • ì‹œë¦¬ì¦ˆë§Œ í¬ë¡¤ë§
        crawl_pitcher_series(
            year=args.year,
            series_key=args.series,
            limit=args.limit,
            headless=args.headless,
            save_to_db=args.save,
        )
    else:
        # ëª¨ë“  ì‹œë¦¬ì¦ˆ í¬ë¡¤ë§ (íƒ€ì í¬ë¡¤ëŸ¬ì™€ ë™ì¼í•œ íŒ¨í„´)
        all_data = {}
        for series_key in SERIES_MAPPING.keys():
            series_info = SERIES_MAPPING[series_key]
            print(f"\nğŸš€ {series_info['name']} ì‹œì‘...")
            series_data = crawl_pitcher_series(
                year=args.year,
                series_key=series_key,
                limit=args.limit,
                headless=args.headless,
                save_to_db=args.save,  # ê° ì‹œë¦¬ì¦ˆë³„ë¡œ ì €ì¥
            )
            all_data[series_key] = series_data
            time.sleep(3)

        # ì „ì²´ ìš”ì•½
        print(f"\n" + "=" * 60)
        print(f"ğŸ“ˆ ì „ì²´ ìˆ˜ì§‘ ìš”ì•½ ({args.year}ë…„)")
        print("=" * 60)
        total_players = 0
        for series_key, data in all_data.items():
            series_name = SERIES_MAPPING[series_key]["name"]
            print(f"  {series_name}: {len(data)}ëª…")
            total_players += len(data)

        print(f"\nì´ ìˆ˜ì§‘ ì„ ìˆ˜: {total_players}ëª…")


if __name__ == "__main__":
    main()
