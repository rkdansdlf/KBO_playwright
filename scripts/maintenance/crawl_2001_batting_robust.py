"""
Robust 2001 batting crawler with ultra-specific selectors and RELIABLE pagination & state reset.
FIXED: Now includes 'season' and 'league' in the data payload (mapped from 'league' key).
"""
import sys
import os
import time
import json
sys.path.insert(0, os.getcwd())

from playwright.sync_api import sync_playwright
from src.utils.team_mapping import get_team_mapping_for_year
from src.crawlers.player_batting_all_series_crawler import (
    get_series_mapping,
    _build_batting_data
)
from src.repositories.safe_batting_repository import save_batting_stats_safe
from src.utils.team_codes import resolve_team_code

def extract_players_custom(page, series_key, year, league_name):
    """Custom JS extraction for BasicOld.aspx"""
    script = """
    () => {
        const table = document.querySelector('table.tData01') || document.querySelector('.record_table table') || document.querySelector('table');
        if (!table) return { error: "Table not found" };
        
        const headers = Array.from(table.querySelectorAll('thead th')).map(th => th.innerText.trim());
        const is_basic2 = headers.join('').includes('BB') || headers.join('').includes('ë³¼ë„·');
        
        const rows = Array.from(table.querySelectorAll('tbody tr'));
        const results = [];
        
        rows.forEach(row => {
            const cells = Array.from(row.querySelectorAll('td'));
            if (cells.length < 10) return;
            
            const nameCell = cells[1];
            const a = nameCell.querySelector('a');
            if (!a) return;
            
            const name = a.innerText.trim();
            const href = a.getAttribute('href') || "";
            const idMatch = href.match(/playerId=(\d+)/);
            const playerId = idMatch ? parseInt(idMatch[1], 10) : null;
            
            if (!playerId) return;
            
            results.push({
                player_id: playerId,
                player_name: name,
                team_name: cells[2].innerText.trim(),
                cells: cells.map(c => c.innerText.trim()),
                is_basic2: is_basic2
            });
        });
        
        return { results };
    }
    """
    try:
        res = page.evaluate(script)
        if "error" in res:
            return []
            
        players = []
        for r in res['results']:
            team_code = resolve_team_code(r['team_name'], year) or r['team_name']
            data = _build_batting_data(
                cells=r['cells'],
                player_id=r['player_id'],
                player_name=r['player_name'],
                team_code=team_code,
                series_key=series_key,
                is_basic2=r['is_basic2']
            )
            data['season'] = year
            # Map 'league' (e.g. 'REGULAR') to the season/league field
            data['league'] = league_name
            data['level'] = 'KBO1'
            data['source'] = 'CRAWLER'
            
            players.append(data)
        return players
    except Exception as e:
        print(f"âš ï¸ Custom extraction error: {e}")
        return []

def robust_crawl_2001():
    year = 2001
    series_key = 'regular'
    mapping = get_series_mapping()
    series_info = mapping[series_key]
    league_name = series_info.get('league') or series_info.get('league_name') or 'REGULAR'
    
    url = "https://www.koreabaseball.com/Record/Player/HitterBasic/BasicOld.aspx"
    
    all_players = {}

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
        page = context.new_page()
        
        print(f"ğŸ“¡ {url} ì ‘ì† ì¤‘...")
        page.goto(url, wait_until="load")
        time.sleep(2)
        
        # Select Year
        season_selector = 'select[name*="ddlSeason"]'
        page.select_option(season_selector, str(year))
        page.wait_for_load_state("networkidle")
        time.sleep(3)
        
        team_selector = 'select[name*="ddlTeam"]'
        options = page.eval_on_selector_all(f'{team_selector} option', 'options => options.map(o => ({text: o.innerText, value: o.value}))')
        teams = [opt for opt in options if opt['value']]
        
        print(f"â„¹ï¸ {len(teams)}ê°œ íŒ€ ë°œê²¬")
        
        for tm in teams:
            print(f"ğŸ” íŒ€ ì„ íƒ: {tm['text']} ({tm['value']})")
            
            # Select team
            page.select_option(team_selector, tm['value'])
            page.wait_for_load_state("networkidle")
            time.sleep(3)
            
            # Reset to Page 1 EXPLICITLY
            try:
                page1_btn = page.query_selector('.paging a[id*="btnNo1"]')
                if page1_btn:
                    print("   â†©ï¸ 1í˜ì´ì§€ë¡œ ë¦¬ì…‹ ì¤‘...")
                    page1_btn.click()
                    page.wait_for_load_state("networkidle")
                    time.sleep(2)
            except:
                pass
            
            page_num = 1
            while True:
                print(f"   ğŸ“„ {tm['text']} - {page_num}í˜ì´ì§€ íŒŒì‹± ì¤‘...")
                
                # Get first player to detect page change later
                first_player_before = page.evaluate("() => document.querySelector('table.tData01 tbody tr td:nth-child(2)')?.innerText.trim()")
                
                players = extract_players_custom(page, series_key, year, league_name)
                
                count_before = len(all_players)
                for p_data in players:
                    pid = p_data.get('player_id')
                    if pid:
                        all_players[pid] = p_data
                
                count_after = len(all_players)
                print(f"   âœ… {len(players)}ëª… íŒŒì‹± (ì‹ ê·œ: {count_after - count_before}ëª…)")
                
                # Pagination
                next_page_num = page_num + 1
                page_btn_selector = f'#cphContents_cphContents_cphContents_udpRecord .paging a[id*="btnNo{next_page_num}"]'
                
                if not page.query_selector(page_btn_selector):
                    page_btn_selector = f'.paging a[href*="btnNo{next_page_num}"]'
                
                btn = page.query_selector(page_btn_selector)
                if btn:
                    print(f"   â¡ï¸ {next_page_num}í˜ì´ì§€ë¡œ ì´ë™ ì¤‘...")
                    btn.click()
                    
                    try:
                        page.wait_for_function(
                            f"oldName => document.querySelector('table.tData01 tbody tr td:nth-child(2)')?.innerText.trim() !== oldName",
                            arg=first_player_before,
                            timeout=5000
                        )
                    except:
                        pass
                    
                    time.sleep(2)
                    page_num += 1
                else:
                    print(f"   ğŸ {tm['text']} ìˆ˜ì§‘ ì™„ë£Œ")
                    break

        browser.close()
        
    final_list = list(all_players.values())
    print(f"âœ… ì´ {len(final_list)}ëª… ìˆ˜ì§‘ ì™„ë£Œ")
    
    if final_list:
        save_batting_stats_safe(final_list)
        print("ğŸ’¾ DB ì €ì¥ ì™„ë£Œ")

if __name__ == "__main__":
    robust_crawl_2001()
